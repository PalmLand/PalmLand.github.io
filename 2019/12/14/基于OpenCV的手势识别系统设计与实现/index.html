<!DOCTYPE html><html lang="zh-Hans" data-theme="light"><head><meta name="generator" content="Hexo 3.8.0"><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><title>基于OpenCV的手势识别系统设计与实现 | PalmLand</title><meta name="description" content="基于OpenCV的手势识别系统设计与实现"><meta name="keywords" content="Machine Learning"><meta name="author" content="PalmLand"><meta name="copyright" content="PalmLand"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/img/bitbug_favicon.ico"><link rel="preconnect" href="//cdn.jsdelivr.net"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:title" content="基于OpenCV的手势识别系统设计与实现"><meta name="twitter:description" content="基于OpenCV的手势识别系统设计与实现"><meta name="twitter:image" content="https://palmland.github.io/img/suoluetu.jpg"><meta property="og:type" content="article"><meta property="og:title" content="基于OpenCV的手势识别系统设计与实现"><meta property="og:url" content="https://palmland.github.io/2019/12/14/基于OpenCV的手势识别系统设计与实现/"><meta property="og:site_name" content="PalmLand"><meta property="og:description" content="基于OpenCV的手势识别系统设计与实现"><meta property="og:image" content="https://palmland.github.io/img/suoluetu.jpg"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><script src="https://cdn.jsdelivr.net/npm/js-cookie/dist/js.cookie.min.js"></script><script>const autoChangeMode = 'false'
var t = Cookies.get("theme");
if (autoChangeMode == '1'){
const isDarkMode = window.matchMedia("(prefers-color-scheme: dark)").matches
const isLightMode = window.matchMedia("(prefers-color-scheme: light)").matches
const isNotSpecified = window.matchMedia("(prefers-color-scheme: no-preference)").matches
const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

if (t === undefined){
  if (isLightMode) activateLightMode()
  else if (isDarkMode) activateDarkMode()
  else if (isNotSpecified || hasNoSupport){
    console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
    now = new Date();
    hour = now.getHours();
    isNight = hour < 6 || hour >= 18
    isNight ? activateDarkMode() : activateLightMode()
}
} else if (t == 'light') activateLightMode()
else activateDarkMode()


} else if (autoChangeMode == '2'){
  now = new Date();
  hour = now.getHours();
  isNight = hour < 6 || hour >= 18
  if(t === undefined) isNight? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode() 
} else {
  if ( t == 'dark' ) activateDarkMode()
  else if ( t == 'light') activateLightMode()
}

function activateDarkMode(){
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null){
    document.querySelector('meta[name="theme-color"]').setAttribute('content','#000')
  }
}
function activateLightMode(){
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null){
  document.querySelector('meta[name="theme-color"]').setAttribute('content','#fff')
  }
}</script><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><link rel="canonical" href="https://palmland.github.io/2019/12/14/基于OpenCV的手势识别系统设计与实现/"><link rel="prev" title="MMDnn框架转换" href="https://palmland.github.io/2020/05/10/MMDnn框架转换/"><link rel="next" title="《机器学习实战》-01参考笔记" href="https://palmland.github.io/2019/08/19/《机器学习实战》-01笔记/"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"We didn't find any results for the search: ${query}"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"cookieDomain":"https://xxx/","msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简"},
  highlight_copy: 'false',
  highlight_lang: 'true',
  highlight_shrink: 'false',
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  bookmark: {
    title: 'Snackbar.bookmark.title',
    message_prev: 'Press',
    message_next: 'to bookmark this page'
  },
  runtime_unit: 'days',
  copyright: undefined,
  copy_copyright_js: false,
  ClickShowText: undefined,
  medium_zoom: 'false',
  Snackbar: undefined
  
}</script></head><body><div id="header"> <div id="page-header"><span class="pull_left" id="blog_name"><a class="blog_title" id="site-name" href="/">PalmLand</a></span><i class="fa fa-bars fa-fw toggle-menu pull_right close" aria-hidden="true"></i><span class="pull_right menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> Link</span></a></div></div></span><span class="pull_right" id="search_button"><a class="site-page social-icon search"><i class="fa fa-search fa-fw"></i><span> Search</span></a></span></div></div><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="lazyload avatar_img" src="/img/me.jpeg" onerror="onerror=null;src='/img/friend_404.gif'"></div><div class="mobile_post_data"><div class="mobile_data_item is_center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">Articles</div><div class="length_num">11</div></a></div></div><div class="mobile_data_item is_center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">Tags</div><div class="length_num">4</div></a></div></div></div><hr><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> Link</span></a></div></div></div><div id="mobile-sidebar-toc"><div class="toc_mobile_headline">Catalog</div><ol class="toc_mobile_items"><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#categories"><span class="toc_mobile_items-number">1.</span> <span class="toc_mobile_items-text">categories:</span></a></li></ol><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#1-基于计算指间夹角数量的手势识别模块实现"><span class="toc_mobile_items-number"></span> <span class="toc_mobile_items-text">1 基于计算指间夹角数量的手势识别模块实现</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#1-1-图像预处理模块"><span class="toc_mobile_items-number">1.</span> <span class="toc_mobile_items-text">1.1    图像预处理模块</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#1-2-轮廓获取模块"><span class="toc_mobile_items-number">2.</span> <span class="toc_mobile_items-text">1.2 轮廓获取模块</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#1-3-特征提取模块"><span class="toc_mobile_items-number">3.</span> <span class="toc_mobile_items-text">1.3 特征提取模块</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#1-4-手势识别模块"><span class="toc_mobile_items-number">4.</span> <span class="toc_mobile_items-text">1.4 手势识别模块</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#2-基于卷积神经网络的手势识别模块实现"><span class="toc_mobile_items-number"></span> <span class="toc_mobile_items-text">2  基于卷积神经网络的手势识别模块实现</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#2-1-图像预处理及数据集生成模块"><span class="toc_mobile_items-number">1.</span> <span class="toc_mobile_items-text">2.1 图像预处理及数据集生成模块</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#2-2-图像大小调整模块"><span class="toc_mobile_items-number">2.</span> <span class="toc_mobile_items-text">2.2 图像大小调整模块</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#2-3-模型训练模块"><span class="toc_mobile_items-number">3.</span> <span class="toc_mobile_items-text">2.3 模型训练模块</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#2-4-手势识别模块"><span class="toc_mobile_items-number">4.</span> <span class="toc_mobile_items-text">2.4 手势识别模块</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#3-基于手势的游戏交互应用"><span class="toc_mobile_items-number"></span> <span class="toc_mobile_items-text">3 基于手势的游戏交互应用</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#4-手势识别效果演示"><span class="toc_mobile_items-number"></span> <span class="toc_mobile_items-text">4 手势识别效果演示</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#4-1-基于计算指间夹角数量的手势识别模块实现"><span class="toc_mobile_items-number">1.</span> <span class="toc_mobile_items-text">4.1 基于计算指间夹角数量的手势识别模块实现</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#4-2-基于卷积神经网络的手势识别模块实现"><span class="toc_mobile_items-number">2.</span> <span class="toc_mobile_items-text">4.2 基于卷积神经网络的手势识别模块实现</span></a></li></ol></li></div></div><div id="body-wrap"><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true">     </i><div class="auto_open" id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">Catalog</div><div class="sidebar-toc__progress"><span class="progress-notice">You've read</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#categories"><span class="toc-number">1.</span> <span class="toc-text">categories:</span></a></li></ol><li class="toc-item toc-level-1"><a class="toc-link" href="#1-基于计算指间夹角数量的手势识别模块实现"><span class="toc-number"></span> <span class="toc-text">1 基于计算指间夹角数量的手势识别模块实现</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-1-图像预处理模块"><span class="toc-number">1.</span> <span class="toc-text">1.1    图像预处理模块</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-2-轮廓获取模块"><span class="toc-number">2.</span> <span class="toc-text">1.2 轮廓获取模块</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-3-特征提取模块"><span class="toc-number">3.</span> <span class="toc-text">1.3 特征提取模块</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-4-手势识别模块"><span class="toc-number">4.</span> <span class="toc-text">1.4 手势识别模块</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#2-基于卷积神经网络的手势识别模块实现"><span class="toc-number"></span> <span class="toc-text">2  基于卷积神经网络的手势识别模块实现</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#2-1-图像预处理及数据集生成模块"><span class="toc-number">1.</span> <span class="toc-text">2.1 图像预处理及数据集生成模块</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-2-图像大小调整模块"><span class="toc-number">2.</span> <span class="toc-text">2.2 图像大小调整模块</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-3-模型训练模块"><span class="toc-number">3.</span> <span class="toc-text">2.3 模型训练模块</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-4-手势识别模块"><span class="toc-number">4.</span> <span class="toc-text">2.4 手势识别模块</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#3-基于手势的游戏交互应用"><span class="toc-number"></span> <span class="toc-text">3 基于手势的游戏交互应用</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#4-手势识别效果演示"><span class="toc-number"></span> <span class="toc-text">4 手势识别效果演示</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#4-1-基于计算指间夹角数量的手势识别模块实现"><span class="toc-number">1.</span> <span class="toc-text">4.1 基于计算指间夹角数量的手势识别模块实现</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-2-基于卷积神经网络的手势识别模块实现"><span class="toc-number">2.</span> <span class="toc-text">4.2 基于卷积神经网络的手势识别模块实现</span></a></li></ol></li></div></div></div><div id="content-outer"><div id="top-container" style="background-image: url(/img/suoluetu.jpg)"><div id="post-info"><div id="post-title"><div class="posttitle">基于OpenCV的手势识别系统设计与实现</div></div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> Created 2019-12-14<span class="post-meta__separator">|</span><i class="fa fa-history" aria-hidden="true"></i> Updated 2020-07-09</time><div class="post-meta-wordcount"></div></div></div></div><div class="layout layout_post" id="content-inner">   <article id="post"><div class="article-container" id="post-content"><h2 id="categories"><a href="#categories" class="headerlink" title="categories:"></a>categories:</h2><ul>
<li>基于计算指间夹角数量的手势识别模块实现</li>
<li>基于卷积神经网络的手势识别模块实现</li>
<li>基于手势的游戏交互应用</li>
</ul>
<a id="more"></a>
<h1 id="1-基于计算指间夹角数量的手势识别模块实现"><a href="#1-基于计算指间夹角数量的手势识别模块实现" class="headerlink" title="1 基于计算指间夹角数量的手势识别模块实现"></a>1 基于计算指间夹角数量的手势识别模块实现</h1><h2 id="1-1-图像预处理模块"><a href="#1-1-图像预处理模块" class="headerlink" title="1.1    图像预处理模块"></a>1.1    图像预处理模块</h2><p>先进行图像预处理减少图像噪声，恢复有用的信息，提高相关信息的可检测性最小化数据，来增强图像分割、匹配和识别的可靠性。</p>
<p>首先使用基于高斯混合的背景/前景分割算法来去除背景，这里使用<code>OpenCV</code>的内置函数<code>createBackgroundSubtractorMOG2()</code>来去除背景。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bgModel = cv2.createBackgroundSubtractorMOG2(0, bgSubThreshold)</span><br></pre></td></tr></table></figure>

<p>然后建立一个背景减法器模型：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fgmask = bgModel.apply(frame)</span><br></pre></td></tr></table></figure>

<p>将模型运用到每一帧上：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">res = cv2.bitwise_and(frame, frame, mask=fgmask)</span><br></pre></td></tr></table></figure>

<p>就能得到如图1-1所示的手的前景图像：<br><img alt="img1-1" data-src="/images/Pro/OpenCV0/11.png" class="lazyload"><br>这样得到的图像还不能将想要的手势从复杂的背景中分离出来，所以还需要进行二值化处理。</p>
<p>先使用<code>cv2.COLOR_BGR2GRAY</code>将RGB图像转化为灰度图：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)</span><br></pre></td></tr></table></figure>

<p>再使用<code>cv2.GaussianBlur()</code>函数用高斯滤波器对图像进行平滑处理，减少噪声：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">blur = cv2.GaussianBlur(gray, (blurValue, blurValue), 0)</span><br></pre></td></tr></table></figure>

<p>最后通过<code>cv2.threshold()</code>进行阈值处理，使得图像的像素值更单一、图像更简单：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ret, thresh = cv2.threshold(blur, threshold, 255, cv2.THRESH_BINARY)</span><br></pre></td></tr></table></figure>

<p>阈值处理是基于特定阈值水平将像素强度分配为0和1，以便仅从图像捕获感兴趣的对象。这样就能从多值的数字图像中直接提取出目标物体。</p>
<p>设计当按下键盘上的“B”时该模块被触发，实现代码如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">elif k == ord(&apos;b&apos;):  # press &apos;b&apos; to capture the background</span><br><span class="line">        bgModel = cv2.createBackgroundSubtractorMOG2(0, bgSubThreshold)</span><br><span class="line">        isBgCaptured = 1</span><br><span class="line">        print( &apos;!!!Background Captured!!!&apos;)</span><br></pre></td></tr></table></figure>

<p>图像预处理结果如图1-2所示：<br><img alt="img1-2" data-src="/images/Pro/OpenCV0/12.png" class="lazyload"></p>
<h2 id="1-2-轮廓获取模块"><a href="#1-2-轮廓获取模块" class="headerlink" title="1.2 轮廓获取模块"></a>1.2 轮廓获取模块</h2><p>使用<code>cv2.findContours()</code>函数查找检测物体的轮廓，然后通过for循环找到区域内最大的轮廓。再根据图像的轮廓点，通过<code>convexhull()</code>函数转化成凸包的点坐标，从而分别画出手和凸包的轮廓。</p>
<p>这个函数将从二值图像中找到所有的轮廓：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">contours,hierarchy=cv2.findContours(thresh1,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)</span><br></pre></td></tr></table></figure>

<p>需要得到手基于其面积的最大轮廓，这里可以假设手是最大的轮廓。使用for循环得到该轮廓：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">for i in range(length):</span><br><span class="line">temp = contours[i]</span><br><span class="line">       area = cv2.contourArea(temp)</span><br><span class="line">           if area &gt; maxArea:</span><br><span class="line">               maxArea = area</span><br><span class="line">               ci = i</span><br></pre></td></tr></table></figure>

<p>根据图像的轮廓点，通过<code>convexHull()</code>函数转化成凸包的点坐标，从而画出图像的凸包。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hull = cv2.convexHull(res)</span><br></pre></td></tr></table></figure>

<p>分别画出手和凸包的轮廓，如图1-3所示，绿色线条为手的轮廓，红色线条是凸包的轮廓。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cv2.drawContours(drawing, [res], 0, (0, 255, 0), 2)</span><br><span class="line">cv2.drawContours(drawing, [hull], 0, (0, 0, 255), 5)</span><br></pre></td></tr></table></figure>

<p>在图1-3中，红色的轮廓线就是凸包<code>(convexity hull)</code>, 而凸包与手掌之间的部分就是凸缺陷<code>(convexity defects)</code>，即对象上的任何凹陷。每个凸缺陷区域有四个特征量：起始点<code>(startPoint)</code>，结束点<code>(endPoint)</code>，距离凸包最远点<code>(farPoint)</code>，最远点到凸包的距离<code>(depth)</code>。如图1-4所示，蓝色的点就是凸缺陷的起始点和结束点，红色的点为最远的点。</p>
<p><img alt="img1-3" data-src="/images/Pro/OpenCV0/13.jpg" class="lazyload"></p>
<p><img alt="img1-4" data-src="/images/Pro/OpenCV0/14.png" class="lazyload"><br>最后使用<code>cv.convexityDefect()</code>函数找到凸缺陷。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">defects = cv2.convexityDefects(res, hull)</span><br></pre></td></tr></table></figure>

<h2 id="1-3-特征提取模块"><a href="#1-3-特征提取模块" class="headerlink" title="1.3 特征提取模块"></a>1.3 特征提取模块</h2><p>图1-4中大拇指和食指构成的三角形可以具体化为图1-5所示的三角形，设定大拇指和食指的夹角为A，其余两个角为B和C，它们的对边分别为a，b，c。<br>如下代码可以计算三角形每边的长度：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># find length of all sides of triangle</span><br><span class="line">a = math.sqrt((end[0] - start[0]) ** 2 + (end[1] - start[1]) ** 2)</span><br><span class="line">b = math.sqrt((far[0] - start[0]) ** 2 + (far[1] - start[1]) ** 2)</span><br><span class="line">c = math.sqrt((end[0] - far[0]) ** 2 + (end[1] - far[1]) ** 2)</span><br></pre></td></tr></table></figure>

<p>使用余弦定理的变形公式（公式(1)）计算角A。</p>
<p>$\cos(A)=(b^2+c^2-a^2)/2bc$   (1)<br><img alt="img1-5" data-src="/images/Pro/OpenCV0/15.jpg" class="lazyload"></p>
<p>然后使用<code>math.acos()</code>函数获得夹角的反余弦弧度值，通过它可以得到手指间的夹角。如果夹角小于90°就视为是两个手指之间的夹角，通过夹角数量来判断手指个数。代码如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">angle = math.acos((b ** 2 + c ** 2 - a ** 2) / (2 * b * c))  </span><br><span class="line">if angle &lt;= math.pi / 2:</span><br><span class="line">		cnt += 1</span><br></pre></td></tr></table></figure>

<h2 id="1-4-手势识别模块"><a href="#1-4-手势识别模块" class="headerlink" title="1.4 手势识别模块"></a>1.4 手势识别模块</h2><p>当按下键盘上的“N”时，系统开始识别手势类型，实现代码如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">elif k == ord(&apos;n&apos;):</span><br><span class="line">    triggerSwitch = True</span><br><span class="line">    print (&apos;!!!Trigger On!!!&apos;)</span><br></pre></td></tr></table></figure>

<p>当该模块被触发时，控制台会输出手势类型，识别代码如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">if triggerSwitch is True:</span><br><span class="line">    if isFinishCal is True:</span><br><span class="line">        print (&quot;finger&quot;+str(cnt+1))# cnt是点的数量，+1表示手指数量</span><br></pre></td></tr></table></figure>

<h1 id="2-基于卷积神经网络的手势识别模块实现"><a href="#2-基于卷积神经网络的手势识别模块实现" class="headerlink" title="2  基于卷积神经网络的手势识别模块实现"></a>2  基于卷积神经网络的手势识别模块实现</h1><h2 id="2-1-图像预处理及数据集生成模块"><a href="#2-1-图像预处理及数据集生成模块" class="headerlink" title="2.1 图像预处理及数据集生成模块"></a>2.1 图像预处理及数据集生成模块</h2><p>手势识别的第一步是通过消除视频序列中的其他不需要的部分来找到手区域。这里使用的是背景消除法，其原理如图2-1所示。<br>这里让系统查看特定场景30帧，在此期间，计算当前帧和前一帧的运行平均值。通过这样做，告诉系统它盯着的这30帧的平均运行视频序列是背景。在弄清楚背景之后，把手放进去，通过背景消除法让系统理解手是前景对象。计算背景模型（随时间更新）和当前帧（有手的帧）之间的绝对差值，以获得保存新添加的前景对象的差异图像。这就是背景消除法的全部内容。<br>为了从这个差异图像中检测手部区域，需要对差异图像进行阈值处理，以便只有手部区域变得可见，而所有其他不需要的区域都被涂成黑色。这就是运动检测的全部意义所在。<br><img alt="img2-1" data-src="/images/Pro/OpenCV0/16.png" class="lazyload"><br>在对差异图像进行阈值处理后，在得到的图像中找到轮廓，假设面积最大的轮廓是手。<br>因此，从视频序列中找到手区域的第一步涉及三个简单步骤：</p>
<p>1) 背景消除法 </p>
<p>2) 运动检测和阈值处理 </p>
<p>3) 轮廓获取</p>
<p>现在，将通过代码实现以上步骤。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">def run_avg(image, aWeight):</span><br><span class="line">    global bg</span><br><span class="line">    # initialize the background</span><br><span class="line">    if bg is None:</span><br><span class="line">        bg = image.copy().astype(&quot;float&quot;)</span><br><span class="line">        return</span><br><span class="line"></span><br><span class="line">    # compute weighted average, accumulate it and update the background</span><br><span class="line">    cv2.accumulateWeighted(image, bg, aWeight)</span><br></pre></td></tr></table></figure>

<p><code>run_avg()</code>函数用于计算背景模型和当前帧之间的运行平均值。此函数接受两个参数:当前帧和aWeight，它类似于在图像上执行运行平均值的阈值。如果背景模型为None（即如果它是第一帧），则用当前帧初始化它。然后，使用<code>cv2.accumulateWeighted()</code>函数计算背景模型和当前帧的运行平均值。运行平均值使用式(2)给出的公式计算:</p>
<p>$dst(x,y)=(1-a).dst(x,y)+a.src(x,y)$  (2)</p>
<ul>
<li>src(x,y):源图像或输入图像（1或3通道，8位或32位浮点数）</li>
<li>dst(x,y):目标图像或输出图像（与源图像相同的通道，32位或64位浮点数）</li>
<li>a:源图像的权重（输入图像）<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">def segment(image, threshold=25):</span><br><span class="line">    global bg</span><br><span class="line">    # find the absolute difference between background and current frame</span><br><span class="line">    diff = cv2.absdiff(bg.astype(&quot;uint8&quot;), image)</span><br><span class="line"></span><br><span class="line">    # threshold the diff image so that we get the foreground</span><br><span class="line">    thresholded = cv2.threshold(diff, threshold, 255, cv2.THRESH_BINARY)</span><br><span class="line">    # get the contours in the thresholded image</span><br><span class="line">    (_, cnts, _) = cv2.findContours(thresholded.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)</span><br><span class="line">    # return None, if no contours detected</span><br><span class="line">    if len(cnts) == 0:</span><br><span class="line">        return</span><br><span class="line">    else:</span><br><span class="line">        # based on contour area, get the maximum contour which is the hand</span><br><span class="line">        segmented = max(cnts, key=cv2.contourArea)</span><br><span class="line">        return (thresholded, segmented)</span><br></pre></td></tr></table></figure>

</li>
</ul>
<p>下一个函数<code>segment()</code>是用于从视频序列中分割手区域。此函数包含两个参数：当前帧和阈值，用于对差值图像进行阈值处理。首先，使用<code>cv2.absdiff()</code>函数找到背景模型和当前帧之间的绝对差异。 接下来，使用<code>cv2.threshold()</code>函数对差异图像进行阈值处理以仅显示手部区域。最后，使用<code>cv2.findContours()</code>函数在阈值图像上执行轮廓获取，并获取具有最大面积的轮廓（这是手）。将阈值图像以及分割图像作为元组返回。如果<code>x(n)</code>表示特定像素坐标处的输入图像的像素强度，则<code>threshold</code>决定将图像分割/阈值到二值图像的程度。</p>
<p>系统必须寻找手区域，因此将尝试最小化识别区域，而不是从整个视频序列中识别手势。要突出显示此区域，使用cv2.rectangle()函数，该函数需要顶部，右侧，底部和左侧像素坐标。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># draw the segmented hand</span><br><span class="line">cv2.rectangle(clone, (left, top), (right, bottom), (0,255,0), 2)</span><br></pre></td></tr></table></figure>

<p>为了跟踪帧数，初始化变量<code>num_frames</code>。然后，开始一个无限循环，并使用<code>camera.read()</code>函数从网络摄像头读取帧。 然后，将输入帧的大小调整为700像素的固定宽度，使用<code>imutils</code>库保持宽高比并翻转帧以避免镜像视图。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># get the current frame</span><br><span class="line">(grabbed, frame) = camera.read()</span><br><span class="line"></span><br><span class="line"># resize the frame</span><br><span class="line">frame = imutils.resize(frame, width=700)</span><br><span class="line"></span><br><span class="line"># flip the frame so that it is not the mirror view</span><br><span class="line">frame = cv2.flip(frame, 1)</span><br></pre></td></tr></table></figure>

<p>接下来，使用简单的<code>NumPy</code>切片仅取出感兴趣的区域（即识别区域）。然后，将此ROI转换为灰度图像，并使用高斯模糊来最小化图像中的高频分量。在超过30帧之前，继续将输入帧添加到<code>run_avg()</code>函数并更新背景模型。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># get the ROI</span><br><span class="line">roi = frame[top:bottom, right:left]</span><br><span class="line"></span><br><span class="line"># convert the roi to grayscale and blur it</span><br><span class="line">gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)</span><br><span class="line">gray = cv2.GaussianBlur(gray, (7, 7), 0)</span><br><span class="line"></span><br><span class="line"># to get the background, keep looking till a threshold is reached</span><br><span class="line"># so that our running average model gets calibrated</span><br><span class="line">if num_frames &lt; 30:</span><br><span class="line">run_avg(gray, aWeight)</span><br><span class="line">print(num_frames)</span><br></pre></td></tr></table></figure>

<p>在更新背景模型之后，将当前输入帧传递到<code>segment()</code>函数中，并返回阈值化图像和分割图像。使用<code>cv2.drawContours()</code>在帧上绘制分段轮廓，并使用<code>cv2.imshow()</code>显示阈值输出。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># segment the hand region</span><br><span class="line">hand = segment(gray)</span><br><span class="line"></span><br><span class="line"># check whether hand region is segmented</span><br><span class="line">if hand is not None:</span><br><span class="line"># if yes, unpack the thresholded image and</span><br><span class="line"># segmented region</span><br><span class="line">        (thresholded, segmented) = hand</span><br><span class="line"></span><br><span class="line">        # draw the segmented region and display the frame</span><br><span class="line">        cv2.drawContours(clone, [segmented + (right, top)], -1, (0, 0, 255))</span><br></pre></td></tr></table></figure>

<p>最后，在当前帧中显示分割的手势区域如图2-2所示，并等待按键退出程序。<br><img alt="img2-2" data-src="/images/Pro/OpenCV0/17.png" class="lazyload"></p>
<p>使用如下代码保存图片，每种手势生成1000张图片作为训练集。该模块原本是想作为基于计算指间夹角数量的手势识别模块的补充，识别手势六到十，但是训练集会过于庞大，训练时间太长，值采集了手势零（握拳）、手势五（手掌）和手势六，生成的部分训练数据如图2-3、2-4、2-5所示。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">if start_recording:</span><br><span class="line"># Mention the directory in which you wanna store the images followed by the image name</span><br><span class="line">cv2.imwrite(&quot;Dataset/FistImages/fist_&quot; + str(image_num) + &apos;.png&apos;, thresholded)</span><br><span class="line">image_num += 1</span><br></pre></td></tr></table></figure>

<p><img alt="img2-3" data-src="/images/Pro/OpenCV0/18.png" class="lazyload"><br><img alt="img2-4" data-src="/images/Pro/OpenCV0/19.png" class="lazyload"><br><img alt="img2-5" data-src="/images/Pro/OpenCV0/20.png" class="lazyload"></p>
<h2 id="2-2-图像大小调整模块"><a href="#2-2-图像大小调整模块" class="headerlink" title="2.2 图像大小调整模块"></a>2.2 图像大小调整模块</h2><p>使用tensorflow设计的卷积神经网络接受89*100的二维单通道图像,因此需要调整图像大小，使用如下代码实现：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">def resizeImage(imageName):</span><br><span class="line">    basewidth = 100</span><br><span class="line">    img = Image.open(imageName)</span><br><span class="line">    wpercent = (basewidth/float(img.size[0]))</span><br><span class="line">    hsize = int((float(img.size[1])*float(wpercent)))</span><br><span class="line">    img = img.resize((basewidth,hsize), Image.ANTIALIAS)</span><br><span class="line">    img.save(imageName)</span><br></pre></td></tr></table></figure>

<h2 id="2-3-模型训练模块"><a href="#2-3-模型训练模块" class="headerlink" title="2.3 模型训练模块"></a>2.3 模型训练模块</h2><p>本次训练模型使用的是TFLearn，TFLearn建立在tensorflow上的一个深度学习库，提供了基于tensorflow的高层API接口，有助于快速构建深度学习网络，大大减少代码冗余。<br>该神经网络包含7个隐藏卷积层，其中relu作为激活函数，1个全连接层。该网络经过50次迭代的训练，每次的batch size为64。<br>现在来定义网络结构的输入层和隐藏层：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">convnet=input_data(shape=[None,89,100,1],name=&apos;input&apos;)</span><br><span class="line">convnet=conv_2d(convnet,32,2,activation=&apos;relu&apos;)</span><br><span class="line">convnet=max_pool_2d(convnet,2)</span><br><span class="line"></span><br><span class="line">convnet=conv_2d(convnet,64,2,activation=&apos;relu&apos;)</span><br><span class="line">convnet=max_pool_2d(convnet,2)</span><br><span class="line"></span><br><span class="line">convnet=conv_2d(convnet,128,2,activation=&apos;relu&apos;)</span><br><span class="line">convnet=max_pool_2d(convnet,2)</span><br><span class="line"></span><br><span class="line">convnet=conv_2d(convnet,256,2,activation=&apos;relu&apos;)</span><br><span class="line">convnet=max_pool_2d(convnet,2)</span><br><span class="line"></span><br><span class="line">convnet=conv_2d(convnet,256,2,activation=&apos;relu&apos;)</span><br><span class="line">convnet=max_pool_2d(convnet,2)</span><br><span class="line"></span><br><span class="line">convnet=conv_2d(convnet,128,2,activation=&apos;relu&apos;)</span><br><span class="line">convnet=max_pool_2d(convnet,2)</span><br><span class="line"></span><br><span class="line">convnet=conv_2d(convnet,64,2,activation=&apos;relu&apos;)</span><br><span class="line">convnet=max_pool_2d(convnet,2)</span><br></pre></td></tr></table></figure>

<p>再来定义全连接层和输出层：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">convnet=fully_connected(convnet,1000,activation=&apos;relu&apos;)</span><br><span class="line">convnet=dropout(convnet,0.75)</span><br><span class="line">convnet=fully_connected(convnet,3,activation=&apos;softmax&apos;)</span><br></pre></td></tr></table></figure>

<p>使用tflearn的DNN类中的fit()函数训练模型：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model.fit(loadedImages, outputVectors, n_epoch=50,</span><br><span class="line">           validation_set = (testImages, testLabels),</span><br><span class="line">           snapshot_step=100, show_metric=True, run_id=&apos;convnet_coursera&apos;)</span><br></pre></td></tr></table></figure>

<p>然后保存模型：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.save(&quot;TrainedModel/GestureRecogModel.tfl&quot;)</span><br></pre></td></tr></table></figure>

<h2 id="2-4-手势识别模块"><a href="#2-4-手势识别模块" class="headerlink" title="2.4 手势识别模块"></a>2.4 手势识别模块</h2><p>先载入之前训练好的模型：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.load(&quot;TrainedModel/GestureRecogModel.tfl&quot;)</span><br></pre></td></tr></table></figure>

<p><code>prefict()</code>函数可以给定输入数据的模型预测，获得预测的手势种类：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">prediction = model.predict([gray_image.reshape(89, 100, 1)])</span><br></pre></td></tr></table></figure>

<p>然后返回预测的手势类型以及概率：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">return np.argmax(prediction), (np.amax(prediction) / (prediction[0][0] + prediction[0][1] + prediction[0][2]))</span><br><span class="line">```</span><br><span class="line">将获得的手势编号转化成手势名称：</span><br><span class="line">```</span><br><span class="line">if predictedClass == 0:</span><br><span class="line">className = &quot;Swing&quot;</span><br><span class="line">elif predictedClass == 1:</span><br><span class="line">className = &quot;Palm&quot;</span><br><span class="line">elif predictedClass == 2:</span><br><span class="line">className = &quot;Fist&quot;</span><br></pre></td></tr></table></figure>

<p>将手势名称及概率显示在屏幕上：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cv2.putText(textImage,&quot;Pedicted Class : &quot; + className, </span><br><span class="line">    (30, 30),  cv2.FONT_HERSHEY_SIMPLEX,  1,  (255, 255, 255),  2)</span><br><span class="line">    cv2.putText(textImage,&quot;Confidence : &quot; + str(confidence * 100) + &apos;%&apos;, </span><br><span class="line">    (30, 100),  cv2.FONT_HERSHEY_SIMPLEX,  1,  (255, 255, 255), 2)</span><br><span class="line">cv2.imshow(&quot;Statistics&quot;, textImage)</span><br></pre></td></tr></table></figure>

<p>得到的效果如图2-6所示：<br><img alt="img2-6" data-src="/images/Pro/OpenCV0/21.png" class="lazyload"></p>
<h1 id="3-基于手势的游戏交互应用"><a href="#3-基于手势的游戏交互应用" class="headerlink" title="3 基于手势的游戏交互应用"></a>3 基于手势的游戏交互应用</h1><p>游戏效果如下图所示：<br><img alt="img3-1" data-src="/images/Pro/OpenCV0/40.png" class="lazyload"><br><img alt="img3-2" data-src="/images/Pro/OpenCV0/41.png" class="lazyload"></p>
<h1 id="4-手势识别效果演示"><a href="#4-手势识别效果演示" class="headerlink" title="4 手势识别效果演示"></a>4 手势识别效果演示</h1><h2 id="4-1-基于计算指间夹角数量的手势识别模块实现"><a href="#4-1-基于计算指间夹角数量的手势识别模块实现" class="headerlink" title="4.1 基于计算指间夹角数量的手势识别模块实现"></a>4.1 基于计算指间夹角数量的手势识别模块实现</h2><p><img alt="img4-1" data-src="/images/Pro/OpenCV0/30.png" class="lazyload"><br><img alt="img4-2" data-src="/images/Pro/OpenCV0/31.jpg" class="lazyload"><br><img alt="img4-3" data-src="/images/Pro/OpenCV0/32.png" class="lazyload"><br><img alt="img4-4" data-src="/images/Pro/OpenCV0/33.png" class="lazyload"><br><img alt="img4-5" data-src="/images/Pro/OpenCV0/34.jpg" class="lazyload"></p>
<h2 id="4-2-基于卷积神经网络的手势识别模块实现"><a href="#4-2-基于卷积神经网络的手势识别模块实现" class="headerlink" title="4.2 基于卷积神经网络的手势识别模块实现"></a>4.2 基于卷积神经网络的手势识别模块实现</h2><p><img alt="img4-6" data-src="/images/Pro/OpenCV0/37.png" class="lazyload"><br><img alt="img4-7" data-src="/images/Pro/OpenCV0/38.png" class="lazyload"><br><img alt="img4-8" data-src="/images/Pro/OpenCV0/39.png" class="lazyload"></p>
</div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined">PalmLand</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="https://palmland.github.io/2019/12/14/基于OpenCV的手势识别系统设计与实现/">https://palmland.github.io/2019/12/14/基于OpenCV的手势识别系统设计与实现/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Machine-Learning/">Machine Learning    </a></div><div class="post_share"><div class="social-share" data-image="/img/suoluetu.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/js/social-share.min.js"></script></div></div><div class="post-reward"><a class="reward-button"><i class="fa fa-qrcode"></i> Donate<div class="reward-main"><ul class="reward-all"><li class="reward-item"><img class="lazyload post-qr-code__img" src="/img/wechat.jpg"><div class="post-qr-code__desc">微信</div></li><li class="reward-item"><img class="lazyload post-qr-code__img" src="/img/alipay.jpg"><div class="post-qr-code__desc">支付寶</div></li></ul></div></a></div><nav class="pagination_post" id="pagination"><div class="prev-post pull_left"><a href="/2020/05/10/MMDnn框架转换/"><img class="prev_cover lazyload" data-src="/img/suoluetu.jpg" onerror="onerror=null;src='/img/suoluetu.jpg'"><div class="label">Previous Post</div><div class="prev_info"><span>MMDnn框架转换</span></div></a></div><div class="next-post pull_right"><a href="/2019/08/19/《机器学习实战》-01笔记/"><img class="next_cover lazyload" data-src="/images/cover/0168.jpg" onerror="onerror=null;src='/img/suoluetu.jpg'"><div class="label">Next Post</div><div class="next_info"><span>《机器学习实战》-01参考笔记</span></div></a></div></nav><div class="relatedPosts"><div class="relatedPosts_headline"><i class="fa fa-fw fa-thumbs-up" aria-hidden="true"></i><span> Recommend</span></div><div class="relatedPosts_list"><div class="relatedPosts_item"><a href="/2019/08/19/《机器学习实战》-01笔记/" title="《机器学习实战》-01参考笔记"><img class="relatedPosts_cover lazyload" data-src="/images/cover/0168.jpg"><div class="relatedPosts_title">《机器学习实战》-01参考笔记</div></a></div></div><div class="clear_both"></div></div></div></div><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2020 By PalmLand</div><div class="framework-info"><span>Driven </span><a href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>Theme </span><a href="https://github.com/jerryc127/hexo-theme-butterfly"><span>Butterfly</span></a></div></div></footer></div><section class="rightside" id="rightside"><div id="rightside-config-hide"><i class="fa fa-book" id="readmode" title="Read Mode"></i><i class="fa fa-plus" id="font_plus" title="Increase font size"></i><i class="fa fa-minus" id="font_minus" title="Decrease font size"></i><a class="translate_chn_to_cht" id="translateLink" href="javascript:translatePage();" title="Traditional Chinese and Simplified Chinese Conversion" target="_self">繁</a><i class="darkmode fa fa-moon-o" id="darkmode" title="Dark Mode"></i></div><div id="rightside-config-show"><div id="rightside_config" title="Setting"><i class="fa fa-cog" aria-hidden="true"></i></div><i class="fa fa-list-ul close" id="mobile-toc-button" title="Table of Contents" aria-hidden="true"></i><i class="fa fa-arrow-up" id="go-up" title="Back to top" aria-hidden="true"></i></div></section><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script async src="/js/search/local-search.js"></script><script src="/js/tw_cn.js"></script><script>translateInitilization()
</script><script src="https://cdn.jsdelivr.net/npm/instant.page@latest/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/lazysizes@latest/lazysizes.min.js" async></script><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">Local search</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="Search for Posts"></div></div></div><hr><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>Powered by</span> <a href="https://github.com/wzpan/hexo-generator-search" style="color:#49B1F5;">hexo-generator-search</a></div></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div></body></html>